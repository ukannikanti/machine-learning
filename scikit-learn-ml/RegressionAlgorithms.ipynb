{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Algorithms:\n",
    "\n",
    "   **Linear Models**\n",
    "       1. Linear Regression\n",
    "       2. Ridge Regression (L2)\n",
    "       3. Lasso Regression (L1)\n",
    "       4. ElasticeNet Regression (L1 + L2)\n",
    "       5. Bayesian Regression\n",
    "       6. SGDRegressor (MSE Loss)\n",
    "       \n",
    "   **Non Linear Models**\n",
    "       1. Kernel Ridge Regression\n",
    "       2. KNN Regression\n",
    "       3. Decision Trees\n",
    "           a. Random Forest (Bagging -> Solves Variance Problem)\n",
    "           b. GradientBoosting/XGBoost (Boosting -> Solves Bias Problem)\n",
    "       4. Guassian Process Regression (RBF Kernel)\n",
    "       \n",
    "      \n",
    "   **Common Loss Functions Used In Regression Algorithms**\n",
    "       1. MSE\n",
    "       2. MAE\n",
    "       3. Huber Loss (Good for outliers)\n",
    "       4. Gini Impurity (Decision Trees)\n",
    "       5. Entropy Loss (Decision Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, RationalQuadratic, ExpSineSquared, ConstantKernel\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing_features_simple_imputer (16512, 13) \n",
      "housing_features_iterative_imputer (16512, 13) \n",
      "housing_features_knn_imputer (16512, 13) \n",
      "housing_labels (16512, 1) \n",
      "test_housing_features (4128, 13) \n",
      "test_housing_labels (4128, 1) \n"
     ]
    }
   ],
   "source": [
    "housing_features_simple_imputer = pd.read_csv(\"/Users/ukannika/work/personal/machine-learning/datasets/housing_features_simple_imputer.csv\", \n",
    "                 sep=\",\", header=None)\n",
    "\n",
    "housing_features_iterative_imputer = pd.read_csv(\"/Users/ukannika/work/personal/machine-learning/datasets/housing_features_iterative_imputer.csv\", \n",
    "                 sep=\",\", header=None)\n",
    "\n",
    "housing_features_knn_imputer = pd.read_csv(\"/Users/ukannika/work/personal/machine-learning/datasets/housing_features_knn_imputer.csv\", \n",
    "                 sep=\",\", header=None)\n",
    "\n",
    "housing_labels = pd.read_csv(\"/Users/ukannika/work/personal/machine-learning/datasets/housing_labels.csv\", sep=\",\", header=None)\n",
    "\n",
    "test_housing_features = pd.read_csv(\"/Users/ukannika/work/personal/machine-learning/datasets/test_housing_features.csv\", sep=\",\", header=None)\n",
    "test_housing_labels = pd.read_csv(\"/Users/ukannika/work/personal/machine-learning/datasets/test_housing_labels.csv\", sep=\",\", header=None)\n",
    "\n",
    "print(\"housing_features_simple_imputer %s \" % (housing_features_simple_imputer.shape,))\n",
    "print(\"housing_features_iterative_imputer %s \" % (housing_features_iterative_imputer.shape,))\n",
    "print(\"housing_features_knn_imputer %s \" % (housing_features_knn_imputer.shape,))\n",
    "print(\"housing_labels %s \" % (housing_labels.shape,))\n",
    "\n",
    "\n",
    "print(\"test_housing_features %s \" % (test_housing_features.shape,))\n",
    "print(\"test_housing_labels %s \" % (test_housing_labels.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "\n",
    "In linear regression, the target value is expected to be a combination of the features.\n",
    "\n",
    "y(W, X) = XW + $\\epsilon$\n",
    "\n",
    "Closed form solution for W\n",
    "\n",
    "W = $(X^TX)^{-1}X^TY$\n",
    "\n",
    "**Cost Function** <br>\n",
    "*MSE(Mean Squared Error)* <br>\n",
    "*MAE(Mean Absolute Error)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 5143803045.215 \n",
      "RMSE : 71720.311 \n",
      "MAE : 71720.311 \n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression().fit(housing_features_simple_imputer, housing_labels)\n",
    "housing_predictions = linear_regression.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 5143803045.215 \n",
      "RMSE : 71720.311 \n",
      "MAE : 71720.311 \n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression().fit(housing_features_iterative_imputer, housing_labels)\n",
    "housing_predictions = linear_regression.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -267243.7579539 ,  -238850.37693415,    54721.32156683,\n",
       "         -169726.57116036,   465832.12901601, -1409050.24035626,\n",
       "          388581.28993895,   563054.30436294,   -18200.31344319,\n",
       "          -58096.30579641,   113221.39522316,   -22237.76246165,\n",
       "          -14687.01352192]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization L1 and L2\n",
    "\n",
    "L1 => Lasso (Sparsity) <br>\n",
    "L2 => Ridge (Shrink weights towards to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 4998357102.495 \n",
      "RMSE : 70699.060 \n",
      "MAE : 70699.060 \n"
     ]
    }
   ],
   "source": [
    "# For this example, we may not see any improve by using Lasso/Ridge Regression.\n",
    "# Tune hyperparameter alpha\n",
    "ridge = Ridge(alpha=0.3, max_iter=10000).fit(housing_features_simple_imputer, housing_labels)\n",
    "housing_predictions = ridge.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 5141196321.752 \n",
      "RMSE : 71702.136 \n",
      "MAE : 71702.136 \n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.3, max_iter=50000).fit(housing_features_simple_imputer, housing_labels)\n",
    "housing_predictions = lasso.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters via grid search\n",
      "Grid search took 0.28 seconds\n",
      "Grid search accuracy: 61.37%\n",
      "Grid search best parameters: {'alpha': 0.30000000000000004}\n"
     ]
    }
   ],
   "source": [
    "# construct the set of hyperparameters to tune\n",
    "print(\"Tuning hyperparameters via grid search\")\n",
    "params = {\"alpha\": np.arange(0.1, 2.0, 0.2)}\n",
    "grid = GridSearchCV(ridge, params)\n",
    "start = time.time()\n",
    "grid.fit(housing_features_simple_imputer, housing_labels)\n",
    "\n",
    "# evaluate the best grid searched model on the testing data\n",
    "print(\"Grid search took {:.2f} seconds\".format(time.time() - start))\n",
    "acc = grid.score(test_housing_features, test_housing_labels)\n",
    "\n",
    "print(\"Grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"Grid search best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor = KNeighborsRegressor(n_neighbors=5, leaf_size=30, p=2, metric='minkowski',\n",
    "                                    weights='uniform', algorithm='ball_tree')\n",
    "\n",
    "print(\"Tuning hyperparameters via grid search\")\n",
    "params = {\"n_neighbors\": np.arange(5, 15, 2), \"leaf_size\": np.arange(10, 30, 2), \"p\" : [1, 2]}\n",
    "grid = GridSearchCV(knn_regressor, params)\n",
    "start = time.time()\n",
    "grid.fit(housing_features_simple_imputer, housing_labels)\n",
    "\n",
    "# evaluate the best grid searched model on the testing data\n",
    "print(\"Grid search took {:.2f} seconds\".format(time.time() - start))\n",
    "acc = grid.score(test_housing_features, test_housing_labels)\n",
    "\n",
    "print(\"Grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"Grid search best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor = KNeighborsRegressor(n_neighbors=9, leaf_size=26, p=2, metric='minkowski',\n",
    "                                    weights='uniform', algorithm='ball_tree').fit(housing_features_simple_imputer, housing_labels)\n",
    "\n",
    "housing_predictions = knn_regressor.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_regressor = SGDRegressor(loss='squared_loss', penalty='l2', alpha=0.01, max_iter=2000, verbose=0, \n",
    "                                        random_state=None, learning_rate='invscaling', \n",
    "                                        eta0=0.01, power_t=0.25, \n",
    "                                        early_stopping=True, validation_fraction=0.1,\n",
    "                                        n_iter_no_change=5, warm_start=False,\n",
    "                                        average=False)\n",
    "\n",
    "sgd_regressor.fit(housing_features_simple_imputer, housing_labels.values.ravel())\n",
    "\n",
    "housing_predictions = sgd_regressor.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees\n",
    "\n",
    "High Depth => High Variance => Bagging <br>\n",
    "Low Depth  => High Bias     => Boosting <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how decision tree with full depth overfit our model. \n",
    "decision_tree_regressor = DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=None, \n",
    "                                  min_samples_split=2, min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, max_features=None, random_state=None, \n",
    "                                  max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                  min_impurity_split=None, presort='deprecated',\n",
    "                                  ccp_alpha=0.0)\n",
    "\n",
    "decision_tree_regressor.fit(housing_features_simple_imputer, housing_labels.values.ravel())\n",
    "\n",
    "\n",
    "housing_predictions = decision_tree_regressor.predict(housing_features_simple_imputer)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better Evaluation Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(estimator=decision_tree_regressor, X=housing_features_simple_imputer, y=housing_labels, \n",
    "                cv=10, scoring=\"neg_mean_squared_error\")\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "print(\"Validation Score %d \" %tree_rmse_scores.mean())\n",
    "\n",
    "\n",
    "## Check prediction score\n",
    "housing_predictions = decision_tree_regressor.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_regressor = RandomForestRegressor(n_estimators=100, criterion='mse',\n",
    "                                             max_depth=None, min_samples_split=5, min_samples_leaf=1, \n",
    "                                             min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                                             min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, \n",
    "                                             oob_score=True, \n",
    "                                             n_jobs=None, random_state=None, verbose=0, \n",
    "                                             warm_start=False, \n",
    "                                             ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "random_forest_regressor.fit(housing_features_simple_imputer, housing_labels.values.ravel())\n",
    "\n",
    "\n",
    "housing_predictions = random_forest_regressor.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_regressor = GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=1000, subsample=1.0, \n",
    "                                      criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, \n",
    "                                      min_weight_fraction_leaf=0.0, max_depth=4, min_impurity_decrease=0.0,\n",
    "                                      min_impurity_split=None, init=None, random_state=None, \n",
    "                                      max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, \n",
    "                                      warm_start=False, presort='deprecated', validation_fraction=0.1,\n",
    "                                      n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "gradient_boosting_regressor.fit(housing_features_simple_imputer, housing_labels.values.ravel())\n",
    "\n",
    "\n",
    "housing_predictions = gradient_boosting_regressor.predict(test_housing_features)\n",
    "\n",
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guassian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_kernel = 10 * RBF(length_scale=10.5) # long term smooth rising trend\n",
    "gaussian_process_regression = GaussianProcessRegressor(kernel=rbf_kernel, alpha=0.001, \n",
    "                                                        optimizer='fmin_l_bfgs_b', n_restarts_optimizer=0, \n",
    "                                                        normalize_y=False, \n",
    "                                                        copy_X_train=False, random_state=None)\n",
    "\n",
    "gaussian_process_regression = gaussian_process_regression.fit(housing_features_simple_imputer, housing_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions, std = gaussian_process_regression.predict(test_housing_features, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Error\n",
    "mse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=True)\n",
    "rmse = mean_squared_error(y_true=test_housing_labels, y_pred=housing_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true=test_housing_labels, y_pred=housing_predictions)\n",
    "\n",
    "print(\"MSE : %0.3f \" % mse)\n",
    "print(\"RMSE : %0.3f \" % rmse)\n",
    "print(\"MAE : %0.3f \" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use this code to view how rbf kernel changes with different parameters\n",
    "def f(x):\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    return x * np.sin(x)\n",
    "\n",
    "X = np.atleast_2d([1., 3., 5., 6., 7., 8.]).T\n",
    "y = f(X).ravel()\n",
    "\n",
    "fig = px.scatter(x=X.ravel(), y=f(X))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_kernel = ConstantKernel(1.0, (1e-3, 10)) * RBF(10, (1e-2, 1e2))\n",
    "gp = GaussianProcessRegressor(kernel=rbf_kernel, n_restarts_optimizer=9)\n",
    "gp.fit(X, y)\n",
    "\n",
    "x = np.atleast_2d(np.linspace(0, 10, 1000)).T\n",
    "y_pred, sigma = gp.predict(x, return_std=True)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(x, f(x), 'r:', label=r'$f(x) = x\\,\\sin(x)$')\n",
    "plt.plot(X, y, 'g.', markersize=10, label='Observations')\n",
    "plt.plot(x, y_pred, 'y-', label='Prediction')\n",
    "\n",
    "plt.fill(np.concatenate([x, x[::-1]]),\n",
    "         np.concatenate([y_pred - 1.9600 * sigma,\n",
    "                        (y_pred + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
