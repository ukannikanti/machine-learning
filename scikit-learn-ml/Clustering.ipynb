{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Algorithms\n",
    "\n",
    "Clustering is the task of grouping a set of objects in sucha way that objects in the same group are more similar to each other than to those in other groups.\n",
    "\n",
    "Types:\n",
    "```\n",
    "1. K means (Centriod Models)\n",
    "2. Guassian Mixture Models (Distribution Models)\n",
    "3. Density Models (DBSCAN)\n",
    "4. Hierarichal Models (Connectivity Models)\n",
    "5. Spectral Clustering (Special Models)\n",
    "```\n",
    "\n",
    "**Cost Functions**\n",
    "\n",
    "*Homogeneity =>  means all of the observations with the same class label are in the same cluster.*\n",
    "\n",
    "*Completeness => means all members of the same class are in the same cluster.*\n",
    "\n",
    "*V-Measure => The V-measure is the harmonic mean between homogeneity and completeness*\n",
    "\n",
    "```\n",
    "sklearn.metrics.homogeneity_score(labels_true, labels_pred)\n",
    "sklearn.metrics.completeness_score(labels_true, labels_pred)\n",
    "sklearn.metrics.v_measure_score(labels_true, labels_pred, beta=1.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_s_curve\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import decomposition\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.metrics import homogeneity_score\n",
    "from sklearn.metrics import completeness_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset1: (1797, 64)\n",
      "Dataset2: (150, 4)\n",
      "Dataset2: (750, 2)\n"
     ]
    }
   ],
   "source": [
    "# Dataset1\n",
    "digits = load_digits()\n",
    "X_digits_features = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Dataset2\n",
    "iris = load_iris()\n",
    "X_iris_features = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Dataset3\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X_blobs, y_blobs = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "print(\"Dataset1: %s\" % (X_digits_features.shape, ))\n",
    "print(\"Dataset2: %s\" % (X_iris_features.shape, ))\n",
    "print(\"Dataset2: %s\" % (X_blobs.shape, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Functions. \n",
    "\n",
    "Documentation Details: https://plot.ly/python/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using plotly\n",
    "def plot_3d_interactive(X_dataset1, y_dataset1, X_dataset2, y_dataset2):\n",
    "    # Initialize figure with subplots\n",
    "    fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[[{\"type\": \"scatter3d\", \"colspan\": 2}, None],\n",
    "           [{\"type\": \"scatter3d\", \"colspan\": 2}, None]],\n",
    "    subplot_titles=(\"Dataset 1\", \"Dataset 2\"))\n",
    "    \n",
    "\n",
    "    trace0 = go.Scatter3d(x=X_dataset1[:, 0], y=X_dataset1[:, 1], z=X_dataset1[:, 2], mode='markers', marker_color=y_dataset1)\n",
    "    trace1 = go.Scatter3d(x=X_dataset2[:, 0], y=X_dataset2[:, 1], z=X_dataset2[:, 2], mode='markers', marker_color=y_dataset2)\n",
    "    \n",
    "    fig.append_trace(trace0, 1, 1)\n",
    "    fig.append_trace(trace1, 2, 1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text='3D subplots with different colorscales',\n",
    "        height=1000,\n",
    "        width=900,\n",
    "        margin=dict(l=0, r=0, b=0, t=0),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using plotly\n",
    "def plot_2d_interactive(X_dataset1, y_dataset1, X_dataset2, y_dataset2):\n",
    "    # Initialize figure with subplots\n",
    "    fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[[{\"type\": \"scatter\", \"colspan\": 2}, None],\n",
    "           [{\"type\": \"scatter\", \"colspan\": 2}, None]],\n",
    "    subplot_titles=(\"Dataset 3\", \"Dataset 4\"))\n",
    "\n",
    "    trace0 = go.Scatter(x=X_dataset1[:, 0], y=X_dataset1[:, 1], mode='markers', marker_color=y_dataset1)\n",
    "    trace1 = go.Scatter(x=X_dataset2[:, 0], y=X_dataset2[:, 1], mode='markers', marker_color=y_dataset2)\n",
    "    \n",
    "    fig.append_trace(trace0, 1, 1)\n",
    "    fig.append_trace(trace1, 2, 1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text='2D subplots with different colorscales',\n",
    "        height=1000,\n",
    "        width=900,\n",
    "        margin=dict(l=0, r=0, b=0, t=0),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Means \n",
    "\n",
    "**n_clusters: Only this parameter is required** \n",
    "    1. The number of clusters to form as well as the number of centroids to generate.\n",
    "    \n",
    "**init** \n",
    "    1.  k-means++ : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. See section Notes in k_init for more details.\n",
    "    2. random: choose k observations (rows) at random from data for the initial centroids.\n",
    "\n",
    "**n_init, default=10** \n",
    "    1. Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_digits = decomposition.PCA(n_components=15)\n",
    "# Fit the model with X and apply the dimensionality reduction on X.\n",
    "X_digits = pca_digits.fit_transform(X_digits_features) \n",
    "\n",
    "pca_iris = decomposition.PCA(n_components=4)\n",
    "# Fit the model with X and apply the dimensionality reduction on X.\n",
    "X_iris = pca_iris.fit_transform(X_iris_features) \n",
    "\n",
    "# init -> selects initial cluster centers for k-mean clustering ('k-means++', 'random')\n",
    "kmeans_digits = KMeans(n_clusters=10, init=\"k-means++\", n_init=10)\n",
    "y_digits_pred = kmeans_digits.fit_predict(X_digits)\n",
    "\n",
    "kmeans_iris = KMeans(n_clusters=10, init=\"k-means++\", n_init=10)\n",
    "y_iris_pred = kmeans_iris.fit_predict(X_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity (Digits): %0.3f\" % homogeneity_score(y_digits, y_digits_pred))\n",
    "print(\"Completeness (Digits): %0.3f\" % completeness_score(y_digits, y_digits_pred))\n",
    "print(\"V-measure (Digits): %0.3f\" % v_measure_score(y_digits, y_digits_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_interactive(X_digits, y_digits_pred, X_iris, y_iris_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guassian Mixture Models\n",
    " \n",
    " A guassian mixture is a function that is comprised of several guassians, each identified by K $\\epsilon$ {1, 2, ... k} where k is the number of clusters in dataset D. \n",
    " \n",
    " Guassian mixture implemented using Expectation Maximization algorithm:\n",
    " \n",
    " 1. Choose initial $\\theta^{old}$.\n",
    " 2. Expectation  Step\n",
    "     q(z) = P(z|X, $\\theta^{old}$)\n",
    " 3. Maximization Step\n",
    "     $\\theta^{New}$ = $argmax_{\\theta}$ $\\sum_{z} q(z)logP(x,z|\\theta)$\n",
    " 4. Iterate till converges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For Visualization purpose \n",
    "pca_digits = decomposition.PCA(n_components=10)\n",
    "# Fit the model with X and apply the dimensionality reduction on X.\n",
    "X_digits = pca_digits.fit_transform(X_digits_features) \n",
    "\n",
    "pca_iris = decomposition.PCA(n_components=3)\n",
    "# Fit the model with X and apply the dimensionality reduction on X.\n",
    "X_iris = pca_iris.fit_transform(X_iris_features) \n",
    "\n",
    "guassian_digits = GaussianMixture(n_components=10, covariance_type='full')\n",
    "y_digits_pred = guassian_digits.fit_predict(X_digits)\n",
    "\n",
    "guassian_iris = GaussianMixture(n_components=3, covariance_type='full')\n",
    "y_iris_pred = guassian_iris.fit_predict(X_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity (Digits): %0.3f\" % homogeneity_score(y_digits, y_digits_pred))\n",
    "print(\"Completeness (Digits): %0.3f\" % completeness_score(y_digits, y_digits_pred))\n",
    "print(\"V-measure (Digits): %0.3f\" % v_measure_score(y_digits, y_digits_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_interactive(X_digits, y_digits_pred, X_iris, y_iris_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density Based Clustering\n",
    "\n",
    "Clustering are defined as areas of higher density than th remainder of the dataset. \n",
    "\n",
    "Points are classified into 3 types\n",
    "1. Core Points => It should have atleast m points are with in distance $\\epsilon$\n",
    "2. Birder Points => Still part of the cluster because its with in $\\epsilon$ of a core point but doesn't meet minimum number of points criteria.\n",
    "3. Noise Points => Not assigned to a cluster\n",
    "\n",
    "```\n",
    "    Important Parameters:\n",
    "    eps => The maximum distance between two samples for one to be considered as in the neighborhood of the other. This is not a maximum bound on the distances of points within a cluster. This is the most important DBSCAN parameter to choose appropriately for your data set and distance function.\n",
    "\n",
    "    min_samples => The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "\n",
    "    algorithm => \n",
    "    The algorithm to be used by the NearestNeighbors module to compute pointwise distances and find nearest neighbors. See NearestNeighbors module documentation for details.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.3, min_samples=10, algorithm=\"ball_tree\")\n",
    "y_pred_blobs = dbscan.fit_predict(X_blobs)\n",
    "print(\"Homogeneity (Blobs): %0.3f\" % homogeneity_score(y_blobs, y_pred_blobs))\n",
    "print(\"Completeness (Blobs): %0.3f\" % completeness_score(y_blobs, y_pred_blobs))\n",
    "print(\"V-measure (Blobs): %0.3f\" % v_measure_score(y_blobs, y_pred_blobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Visualization purpose \n",
    "pca_digits = decomposition.PCA(n_components=15)\n",
    "# Fit the model with X and apply the dimensionality reduction on X.\n",
    "X_digits = pca_digits.fit_transform(X_digits_features) \n",
    "\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=10, algorithm=\"ball_tree\")\n",
    "y_pred_digits = dbscan.fit_predict(X_digits)\n",
    "print(\"Homogeneity (Digits): %0.3f\" % homogeneity_score(y_digits, y_pred_digits))\n",
    "print(\"Completeness (Digits): %0.3f\" % completeness_score(y_digits, y_pred_digits))\n",
    "print(\"V-measure (Digits): %0.3f\" % v_measure_score(y_digits, y_pred_digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heirarichal Clustering\n",
    "\n",
    "Starts with one cluster, individual item in its own cluster and iteratively merge clusters until all the items belong to one cluster.\n",
    "\n",
    "Single Linkage:\n",
    " D(C1, C2) = $min_{x1 \\epsilon C1; x2 \\epsilon C2}$ D(x1, x2) \n",
    "\n",
    "Complete Linkage:\n",
    " D(C1, C2) = $max_{x1 \\epsilon C1; x2 \\epsilon C2}$ D(x1, x2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_digits = AgglomerativeClustering(n_clusters=10, linkage='complete')\n",
    "y_digits_pred = agglomerative_digits.fit_predict(X_digits_features)\n",
    "\n",
    "agglomerative_iris = AgglomerativeClustering(n_clusters=3, linkage='complete')\n",
    "y_iris_pred = agglomerative_iris.fit_predict(X_iris_features)\n",
    "\n",
    "agglomerative_blobs = AgglomerativeClustering(n_clusters=3, linkage='complete')\n",
    "y_blobs_pred = agglomerative_iris.fit_predict(X_blobs)\n",
    "y_blobs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity (Digits): %0.3f\" % homogeneity_score(y_digits, y_digits_pred))\n",
    "print(\"Completeness (Digits): %0.3f\" % completeness_score(y_digits, y_digits_pred))\n",
    "print(\"V-measure (Digits): %0.3f\" % v_measure_score(y_digits, y_digits_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity (Digits): %0.3f\" % homogeneity_score(y_iris, y_iris_pred))\n",
    "print(\"Completeness (Digits): %0.3f\" % completeness_score(y_iris, y_iris_pred))\n",
    "print(\"V-measure (Digits): %0.3f\" % v_measure_score(y_iris, y_iris_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity (Digits): %0.3f\" % homogeneity_score(y_blobs, y_blobs_pred))\n",
    "print(\"Completeness (Digits): %0.3f\" % completeness_score(y_blobs, y_blobs_pred))\n",
    "print(\"V-measure (Digits): %0.3f\" % v_measure_score(y_blobs, y_blobs_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Visualization purpose \n",
    "pca_digits = decomposition.PCA(n_components=10)\n",
    "# Fit the model with X and apply the dimensionality reduction on X.\n",
    "X_digits = pca_digits.fit_transform(X_digits_features) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure graph is fully connected. \n",
    "spectral_digits = SpectralClustering(n_clusters=10, n_components=3, affinity='rbf', assign_labels='kmeans', n_init=10)\n",
    "y_pred_digits = spectral_digits.fit_predict(X_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity (Digits): %0.3f\" % homogeneity_score(y_digits, y_pred_digits))\n",
    "print(\"Completeness (Digits): %0.3f\" % completeness_score(y_digits, y_pred_digits))\n",
    "print(\"V-measure (Digits): %0.3f\" % v_measure_score(y_digits, y_pred_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
