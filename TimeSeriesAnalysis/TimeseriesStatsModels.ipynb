{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from math import sin\n",
    "from math import radians\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.arima.model import ARIMA \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas_datareader.data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries Analysis using Statistics.\n",
    "\n",
    "**Preprocessing Steps for Timeseries Analysis.**\n",
    "In time series, we need to make the timeseries stationary. For that we need to remove trends and seasonality in timeseries data. \n",
    "\n",
    "    Trends: \n",
    "        Linear Trend\n",
    "        Exponential Trend (Apply log function to convert the exponential to linear)\n",
    "        \n",
    "    Seasional:\n",
    "        Periods\n",
    "        \n",
    "***Remove Trend/Seasonality in timeseries***\n",
    "\n",
    "    Methods:\n",
    "        1. Subtract the rolling mean\n",
    "        2. Differencing\n",
    "        3. Decomposition.\n",
    "        \n",
    "You can use any of the above methods to remove trend and make it stationary. \n",
    "     \n",
    "     \n",
    "**Stat Models**\n",
    "\n",
    "    1. AR Model\n",
    "    2. MA Model\n",
    "    3. ARMA Model\n",
    "    4. ARIMA Model\n",
    "    5. ARCH Model\n",
    "    6. GRACH Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateparser(s):\n",
    "    return datetime.strptime(s, '%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/AirPassengers.csv', parse_dates=['Month'], index_col='Month')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Stationarity.\n",
    "\n",
    "Verify constant mean, constant variance and autocovariance not a function of time t. \n",
    "\n",
    "Ways to validate:\n",
    "    1. Visual Representaion\n",
    "    2. Dickey-Fuller Test(Statistical Test)\n",
    "\n",
    "The Augmented Dickey-Fuller test can be used to test for a unit root in a univariate process in the presence of serial correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual Representaion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = data['#Passengers'] \n",
    "plt.plot(ts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, mean and variance of this time series is changing over time and it is a linear trend  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dickey-Fuller Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Dickey-Fuller test:\n",
    "dftest = adfuller(ts, autolag='AIC')\n",
    "\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "# Here null hypothesis is there exists a unit root in time series data. \n",
    "# If p-value > 0.5, for sure there exists a unit root.\n",
    "# Check if p-value < alpha (1%, 5% 10%) to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here p-value is greater than 0.5, which means there exists a unit root. This timeseries is not stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log to make it linear trend.\n",
    "ts_log = np.log(ts)\n",
    "plt.plot(ts_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "\n",
    "${n}_t = \\frac{{v}_t - \\mu}{\\sigma}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(ts_log)\n",
    "std = np.std(ts_log)\n",
    "\n",
    "ts_norm = (ts_log - mean)/std\n",
    "plt.plot(ts_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Dickey-Fuller test:\n",
    "dftest = adfuller(ts_norm, autolag='AIC')\n",
    "\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Subtract the rolling mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average\n",
    "moving_avg = ts_norm.rolling(window=12, center=False).mean()\n",
    "plt.plot(ts_norm)\n",
    "plt.plot(moving_avg, color='red')\n",
    "\n",
    "#rolstd = ts_log.rolling(window=12, center=False).std()\n",
    "#plt.plot(rolstd, color='black', label= Rolling Std')\n",
    "#plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove trend from original data\n",
    "ts_log_moving_avg_diff = ts_norm - moving_avg\n",
    "ts_log_moving_avg_diff.dropna(inplace=True)\n",
    "\n",
    "# Calculate current mean for plotting. \n",
    "moving_avg = ts_log_moving_avg_diff.rolling(window=12, center=False).mean()\n",
    "rolstd = ts_log_moving_avg_diff.rolling(window=12, center=False).std()\n",
    "\n",
    "# Plot\n",
    "plt.plot(ts_log_moving_avg_diff, label=\"diff orig\")\n",
    "plt.plot(moving_avg, color='red', label='mean')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Differencing**\n",
    "\n",
    "Differencing can help stabilize the mean of the time series by removing changes in the level of a time series, and so eliminating (or reducing) trend and seasonality\n",
    "\n",
    "Lag Difference\n",
    "\n",
    "    Taking the difference between consecutive observations is called a lag-1 difference.\n",
    "\n",
    "    The lag difference can be adjusted to suit the specific temporal structure.\n",
    "\n",
    "    For time series with a seasonal component, the lag may be expected to be the period (width) of the seasonality.\n",
    "\n",
    "Difference Order\n",
    "\n",
    "    Some temporal structure may still exist after performing a differencing operation, such as in the case \n",
    "    of a nonlinear trend.\n",
    "\n",
    "    As such, the process of differencing can be repeated more than once until all temporal dependence has \n",
    "    been removed.\n",
    "\n",
    "    The number of times that differencing is performed is called the difference order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, value):\n",
    "    return value + last_ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing with custom function.\n",
    "diffdata = difference(ts_norm, interval = 1)\n",
    "pyplot.plot(diffdata)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to do differencing.\n",
    "diff = ts_norm.diff(periods=1).dropna()\n",
    "moving_avg = diff.rolling(window=12, center=False).mean()\n",
    "\n",
    "pyplot.plot(diff)\n",
    "plt.plot(moving_avg, color='red', label='mean')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Dickey-Fuller test:\n",
    "dftest = adfuller(diff, autolag='AIC')\n",
    "\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(ts_norm, model='additive', period=12)\n",
    "trend = decomposition.trend.dropna()\n",
    "seasonal = decomposition.seasonal.dropna()\n",
    "residual = decomposition.resid.dropna()\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(ts_log, label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trend)\n",
    "print(seasonal)\n",
    "print(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = residual.rolling(window=12, center=False).mean()\n",
    "pyplot.plot(residual)\n",
    "plt.plot(moving_avg, color='red', label='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adfuller(residual, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Train and Test Data\n",
    "# In timeseries data, make sure when we split the data, order is not changed.\n",
    "# We need to maintain order of the timeseries.\n",
    "train_end_date = datetime(1959, 12, 1)\n",
    "test_date = datetime(1960, 12, 1)\n",
    "\n",
    "train_data = residual[:train_end_date]\n",
    "test_data = ts[train_end_date + timedelta(days=1):test_date]\n",
    "\n",
    "train_data.index = pd.DatetimeIndex(train_data.index.values, freq=train_data.index.inferred_freq)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. AR Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the order for AR model using PACF. \n",
    "plot_pacf(train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at this plot, we can set order to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armodel = ARIMA(train_data, order=(4,0,0))\n",
    "armodel_fit = armodel.fit()\n",
    "print(armodel_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Operations applied on timeseries data.\n",
    "\n",
    "*1. Exponential trend to linear by applying log function.*\n",
    "    \n",
    "${l}_t = \\log({{x}_t})$\n",
    "    \n",
    "*2. Normalize the data*\n",
    "\n",
    "${n}_t = \\frac{{v}_t - \\mu}{\\sigma}$\n",
    "\n",
    "*3. Seasonal Decomposition*\n",
    "    \n",
    "    trend\n",
    "    seasional\n",
    "    residual\n",
    "\n",
    "\n",
    "Now, after forecasting the data, convert the results back to its original form.\n",
    "\n",
    "1. Results = ${y}_t$\n",
    "\n",
    "2. Add trend, seasionality to results.\n",
    "\n",
    "3. ${o}_t = {y}_t .{\\sigma} + \\mu$\n",
    "\n",
    "4. $\\varepsilon^{{o}_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast for next 12 months\n",
    "results = armodel_fit.forecast(6)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo transformations. In decomposition, \n",
    "# as it does symmetry moving average, it will remove first 6 months and last 6 months of data.\n",
    "trend1 = trend[train_end_date + timedelta(days=1):test_date]\n",
    "seasonal1 = seasonal[train_end_date + timedelta(days=1):test_date]\n",
    "results = results + trend1 + seasonal1\n",
    "predictions = np.exp(results * std + mean)\n",
    "predictions = predictions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(predictions, test_data[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.plot(ts)\n",
    "plt.plot(predictions)\n",
    "\n",
    "plt.legend(('Data', 'Predictions'), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Price Predictions.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2020, 9, 14)\n",
    "\n",
    "dis = pdr.DataReader('MSFT', 'yahoo', start=start, end=end)\n",
    "dis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply time series analysis on close. \n",
    "data = dis['Close']\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(data)\n",
    "plt.ylabel('End of closing day price', fontsize=16)\n",
    "plt.title('Stock', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Dickey-Fuller test:\n",
    "dftest = adfuller(data, autolag='AIC')\n",
    "\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log to make it linear trend.\n",
    "stock_ts_log = np.log(data)\n",
    "plt.plot(stock_ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "stock_mean = np.mean(stock_ts_log)\n",
    "stock_std = np.std(stock_ts_log)\n",
    "\n",
    "stock_ts_norm = (stock_ts_log - stock_mean)/stock_std\n",
    "plt.plot(stock_ts_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trend and seasonality in timeseries data. \n",
    "decomposition = seasonal_decompose(stock_ts_norm, model='additive', period = 7)\n",
    "trend = decomposition.trend.dropna()\n",
    "seasonal = decomposition.seasonal.dropna()\n",
    "residual = decomposition.resid.dropna()\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(ts_log, label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = residual.rolling(window=7, center=False).mean()\n",
    "pyplot.plot(residual)\n",
    "plt.plot(moving_avg, color='red', label='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adfuller(residual, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Train and Test Data\n",
    "# In timeseries data, make sure when we split the data, order is not changed.\n",
    "# We need to maintain order of the timeseries.\n",
    "train_end_date = datetime(2020, 9, 6)\n",
    "test_date = datetime(2020, 9, 11)\n",
    "\n",
    "train_data = residual[:train_end_date]\n",
    "test_data = data[train_end_date + timedelta(days=1):test_date]\n",
    "\n",
    "train_data.index = pd.DatetimeIndex(train_data.index.values)\n",
    "\n",
    "print(train_data)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the order for AR model using PACF. \n",
    "plot_pacf(train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armodel = ARIMA(train_data, order=(5,0,0))\n",
    "armodel_fit = armodel.fit()\n",
    "print(armodel_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast for next 12 months\n",
    "results = armodel_fit.forecast(4)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at neural networks for more advanced approaches. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
