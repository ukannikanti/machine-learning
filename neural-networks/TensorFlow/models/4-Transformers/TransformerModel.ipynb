{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer model for language understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Sample Data\n",
    "for i in train_examples.take(1):\n",
    "    print(i[0].numpy())\n",
    "    print(i[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom subwords tokenizer from the training dataset.\n",
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary.\n",
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a start and end token to the input and target.\n",
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "        lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "        lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "\n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_smaple in train_examples.take(1):\n",
    "    lang1, lang2 = encode(input_smaple[1], input_smaple[0])\n",
    "    print(lang1, lang2)\n",
    "    \n",
    "    for ts in lang2:\n",
    "        print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))\n",
    "        \n",
    "    for ts in lang2:\n",
    "        print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "\n",
    "    return result_pt, result_en\n",
    "\n",
    "# Note: To keep this example small and relatively fast, drop examples with a length of over 40 tokens.\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "print(x)\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled dot product attention\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead) \n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "      Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable \n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "      Returns:\n",
    "        output, attention_weights\n",
    "      \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn)\n",
    "    print ('Output is:')\n",
    "    print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "          tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "      ])\n",
    "\n",
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder layer\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder.\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input & Output Shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "# Define loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "The following steps are used for evaluation:\n",
    "\n",
    "    Encode the input sentence using the Portuguese tokenizer (tokenizer_pt). Moreover, add the start and end\n",
    "    token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "    \n",
    "    The decoder input is the start token == tokenizer_en.vocab_size.\n",
    "    \n",
    "    Calculate the padding masks and the look ahead masks.\n",
    "    \n",
    "    The decoder then outputs the predictions by looking at the encoder output and its own output (self-attention).\n",
    "    \n",
    "    Select the last word and calculate the argmax of that.\n",
    "    \n",
    "    Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "    \n",
    "    In this approach, the decoder predicts the next word based on the previous words it predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_pt.vocab_size]\n",
    "    end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "    \n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    decoder_input = [tokenizer_en.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer_en.vocab_size+1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, attention_weights = evaluate(\"este  um problema que temos que resolver.\")\n",
    "\n",
    "print(result)\n",
    "\n",
    "predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size]) \n",
    "\n",
    "print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
