{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# our model focuses on during captioning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn includes many helpful utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications:\n",
    "    \n",
    "    The main goal of RNN is to solve sequence learning problems. \n",
    "    \n",
    "    1. Sentiment Analysis (with and without pre-trained embeddings)\n",
    "    2. Machine Translation\n",
    "    3. Text Generation\n",
    "    4. Timeseries Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM/GRU  Input Shape\n",
    "\n",
    "    LSTM/GRU Layer only accepts only input shape  of 3D tensor, with shape [batch, timesteps, feature].\n",
    "    \n",
    "    Batch: One sequence is one sample. A batch is comprised of one or more samples.\n",
    "    Time Steps: One time step is one point of observation in the sample.\n",
    "    Features: One feature is one observation at a time step.\n",
    "    \n",
    "    \n",
    "    \n",
    "timesteps => *The number of time steps is equal to the number of LSTM cells*\n",
    "\n",
    "features => *The features is equal to the number of features in the dataset.*\n",
    "\n",
    "The batch_size in the 3D tensor of the shape [batch_size, timesteps, input_dim] may not need to be specified and can be specified just to speed up the training process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.79720545 -0.42998615]\n",
      "  [-2.4812086   0.7619795 ]]], shape=(1, 2, 2), dtype=float32)\n",
      "(1, 2, 2) \n",
      "\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "# [batch, timesteps, feature] => [1, 2, 2]\n",
    "inputs = tf.random.normal([1, 2, 2])\n",
    "print(inputs)\n",
    "print(inputs.shape, \"\\n\")\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(4)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Load Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
    "train_examples, test_examples = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8185\n",
      "Encoded string is [4025, 222, 6307, 2327, 4043, 2120, 7975]\n",
      "The original string: \"Hello TensorFlow.\"\n",
      "4025 ----> Hell\n",
      "222 ----> o \n",
      "6307 ----> Ten\n",
      "2327 ----> sor\n",
      "4043 ----> Fl\n",
      "2120 ----> ow\n",
      "7975 ----> .\n"
     ]
    }
   ],
   "source": [
    "encoder = info.features['text'].encoder\n",
    "print('Vocabulary size: {}'.format(encoder.vocab_size))\n",
    "\n",
    "\n",
    "sample_string = 'Hello TensorFlow.'\n",
    "\n",
    "encoded_string = encoder.encode(sample_string)\n",
    "print('Encoded string is {}'.format(encoded_string))\n",
    "\n",
    "original_string = encoder.decode(encoded_string)\n",
    "print('The original string: \"{}\"'.format(original_string))\n",
    "\n",
    "# Decode Example:\n",
    "for index in encoded_string:\n",
    "    print('{} ----> {}'.format(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand how to structure the data for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n",
      "[1]\n",
      "[2 2]\n",
      "[3 3 3]\n",
      "[4 4 4 4]\n",
      "\n",
      " After Padding\n",
      "[[1 0 0 0 0]\n",
      " [2 2 0 0 0]]\n",
      "[[3 3 3 0 0]\n",
      " [4 4 4 4 0]]\n"
     ]
    }
   ],
   "source": [
    "A = (tf.data.Dataset.range(1, 5).map(lambda x: tf.fill([x], x)))\n",
    "\n",
    "print(\"Original Data\")\n",
    "for element in A.as_numpy_iterator():\n",
    "    print(element)\n",
    "    \n",
    "print(\"\\n After Padding\")\n",
    "    \n",
    "B = A.padded_batch(2, padded_shapes=5)\n",
    "for element in B.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = (train_examples.take(10000).shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[])))\n",
    "test_dataset = (test_examples.padded_batch(BATCH_SIZE,  padded_shapes=([None],[])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=1,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model does not mask the padding applied to the sequences. This can lead to skew if trained on padded sequences and test on un-padded sequences. Ideally you would use masking to avoid this, but as you can see below it only have a small effect on the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding\n",
    "\n",
    "    When processing sequence data, it is very common for individual samples to have different lengths. Consider the following example (text tokenized as words)\n",
    "    \n",
    "    The data is a 2D list where individual samples have length 6, 5, and 3 respectively. Since the input data for a \n",
    "    deep learning model must be a single tensor (of shape e.g. (batch_size, 6, vocab_size) in this case), samples \n",
    "    that are shorter than the longest item need to be padded with some placeholder value (alternatively, one might \n",
    "    also truncate long samples before padding short samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  [\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\"],\n",
    "  [\"How\", \"are\", \"you\", \"doing\", \"today\"],\n",
    "  [\"Hello\", \"world\", \"!\"]\n",
    "]\n",
    "\n",
    "# Now assume that, After vocabulary lookup\n",
    "\n",
    "raw_inputs = [\n",
    "  [83, 91, 1, 645, 1253, 927],\n",
    "  [73, 8, 3215, 55, 927],\n",
    "  [711, 632, 71]\n",
    "]\n",
    "\n",
    "\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs, padding='post')\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking \n",
    "\n",
    "    Now that all samples have a uniform length, the model must be informed that some part of the data is actually \n",
    "    padding and should be ignored. That mechanism is masking\n",
    "    \n",
    "    \"Masking\" is how layers are able to know when to skip / ignore certain timesteps in sequence inputs.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "\n",
    "print(masked_output._keras_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the printed result, the mask is a 2D boolean tensor with shape (batch_size, sequence_length), where each individual False entry indicates that the corresponding timestep should be ignored during processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_size(vec, size):\n",
    "    zeros = [0] * (size - len(vec))\n",
    "    vec.extend(zeros)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict(sample_pred_text, pad):\n",
    "    encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
    "\n",
    "    if pad:\n",
    "        encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "    \n",
    "    encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "    predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "\n",
    "    return (predictions)\n",
    "\n",
    "# predict on a sample text without padding.\n",
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "# predict on a sample text with padding\n",
    "\n",
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "\n",
    "predictions = sample_predict(sample_pred_text, pad=True)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD More Layers & Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history1 = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "# predict on a sample text with padding\n",
    "\n",
    "sample_pred_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=True)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
